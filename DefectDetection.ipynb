{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in our Data using ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"casting_data\"\n",
    "\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "\n",
    "    with zipfile.ZipFile(data_path / \"casting_data.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "random.seed()\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpeg\"))\n",
    "random_image_path = random.choice(image_path_list)\n",
    "image_class = random_image_path.parent.stem #here we're essentially using the name of the folder to define the image class\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization using matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn the image into an array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming/augmenting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "data_transform = v2.Compose([\n",
    "                v2.Resize(size=(224, 224)),\n",
    "                v2.ToTensor()])\n",
    "\n",
    "#original\n",
    "train_data_transform = v2.Compose([\n",
    "                v2.Resize(size=(224, 224)),\n",
    "                v2.RandomHorizontalFlip(p = 0.5),\n",
    "                v2.ColorJitter(brightness = (0.7, 1.3), contrast = (0.7, 1.3), saturation = (0.7, 1.3), hue = (-0.3, 0.3)),\n",
    "                v2.RandomVerticalFlip(p = 0.5),\n",
    "                #v2.Grayscale(num_output_channels= 1),\n",
    "                v2.ToTensor()])\n",
    "\n",
    "#Testing out some different augmentations\n",
    "train_data_transform2 = v2.Compose([\n",
    "                v2.Resize(size=(224, 224)),\n",
    "                v2.RandomHorizontalFlip(p = 0.3),\n",
    "                v2.ColorJitter(brightness = (0.7, 1.3), contrast = (0.7, 1.3), saturation = (0.7,1.3), hue = (-0.3, 0.3)),\n",
    "                v2.RandomInvert(p = 0.05),\n",
    "                v2.RandomAdjustSharpness(3, p = 0.05),\n",
    "                v2.RandomVerticalFlip(p = 0.3),\n",
    "                v2.ToTensor()])\n",
    "\n",
    "test_data_transform = v2.Compose([\n",
    "                v2.Resize(size=(224, 224)),\n",
    "                #v2.Grayscale(num_output_channels= 1),\n",
    "                v2.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "#print(data_transform(img))\n",
    "print(data_transform(img).shape)\n",
    "print(data_transform(img).dtype)\n",
    "\n",
    "#print(train_data_transform(img))\n",
    "print(train_data_transform(img).shape)\n",
    "print(train_data_transform(img).dtype)\n",
    "\n",
    "#print(test_data_transform(img))\n",
    "print(test_data_transform(img).shape)\n",
    "print(test_data_transform(img).dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n = 5, seed = None):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n) #taking a random sample from image_paths, k = n images\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "            # Transforming and plotting images, permute() will change shape of images to suit matplotlib (PyTorch default is [C, H, W], matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image) \n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=train_data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=train_data_transform)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=test_data_transform)\n",
    "\n",
    "image, label = train_data[0]\n",
    "image, label\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape) #dimensions are color channels, height and width\n",
    "print(label)\n",
    "\n",
    "\n",
    "print(train_data.classes)\n",
    "print(train_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting attributes of the data\n",
    "class_names = train_data.classes\n",
    "class_dict = train_data.class_to_idx #target values of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "\n",
    "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
    "\n",
    "random.seed(42)\n",
    "train_dataloader = DataLoader(train_data, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, \n",
    "                            num_workers=NUM_WORKERS)\n",
    "random.seed(42)\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            shuffle=False, \n",
    "                            num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels=64, kernel_size=3, stride=1, padding=2),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p = 0.05),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 64, out_channels= 64, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels = 64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p = 0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels = 128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels = 128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p = 0.05),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            #nn.AdaptiveAvgPool2d(output_size =(14, 14))\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*7*7, out_features=32*7*7),\n",
    "            #nn.BatchNorm2d(32*7*7),\n",
    "            nn.Linear(in_features=32*7*7, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.block1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = CNN().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.0005)#, weight_decay = 1e-4)\n",
    "from torcheval import torcheval\n",
    "from torcheval.metrics.functional.classification import binary_recall \n",
    "from torcheval.metrics.functional.classification import binary_precision\n",
    "from torcheval.metrics.functional.classification import binary_f1_score\n",
    "from torcheval.metrics.functional.classification import binary_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_binary(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    random.seed(42)\n",
    "    \n",
    "    model.train()\n",
    "    train_loss, train_acc, train_recall, train_precision, train_f1 = 0, 0, 0, 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        train_pred = model(X).squeeze()  # Remove the extra dimension\n",
    "        loss = loss_fn(train_pred, y.float())  # Ensure y is of float type \n",
    "        train_loss += loss.item() # total loss over all batches\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()      \n",
    "        train_pred_binary = torch.round(train_pred)\n",
    "        train_acc += (train_pred_binary == y).sum().item()/len(train_pred_binary)\n",
    "        train_recall += binary_recall(train_pred_binary, y).item()\n",
    "        train_precision += binary_precision(train_pred_binary, y).item()\n",
    "        train_f1 += binary_f1_score(train_pred_binary, y).item()\n",
    "        avg_train_recall = train_recall / (batch + 1)\n",
    "        avg_train_precision = train_precision / (batch + 1)\n",
    "        avg_train_loss = train_loss / (batch + 1)\n",
    "        if batch % 1 == 0 and batch > 0:\n",
    "            print(f\"Training Batch {batch}/{len(dataloader)} | Training Loss: {avg_train_loss}\")\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    train_recall = train_recall / len(dataloader)\n",
    "    train_precision = train_precision / len(dataloader)\n",
    "    train_f1 = train_f1 / len(dataloader)\n",
    "    return train_loss, train_acc, train_recall, train_precision, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step_binary(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    model.eval() \n",
    "    test_loss, test_acc, test_recall, test_precision, test_f1 = 0, 0, 0, 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = y.to(torch.float32)\n",
    "            test_pred = model(X).squeeze()\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_pred_binary = torch.round(test_pred)\n",
    "            test_acc += (test_pred_binary == y).sum().item()/len(test_pred_binary)\n",
    "            test_recall += binary_recall(test_pred_binary, y).item()\n",
    "            test_precision += binary_precision(test_pred_binary, y).item()\n",
    "            test_f1 += binary_f1_score(test_pred_binary, y).item()\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    test_recall = test_recall / len(dataloader)\n",
    "    test_precision = test_precision / len(dataloader)\n",
    "    test_f1 = test_f1 / len(dataloader)\n",
    "    return test_loss, test_acc, test_recall, test_precision, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int):\n",
    "\n",
    "\n",
    "    # 2. Create empty results dictionary\n",
    "    #results = {\"train_loss\": [],\n",
    "    #    \"train_acc\": [],\n",
    "    #    \"test_loss\": [],\n",
    "    #    \"test_acc\": [],\n",
    "    #}\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"\\n|-|-|-|-|-|-|-|-|-|-|-|-|-| BEGINNING EPOCH {epoch + 1} |-|-|-|-|-|-|-|-|-|-|-|-|-|\\n\")\n",
    "        \n",
    "        train_loss, train_acc, train_recall, train_precision, train_f1 = train_step_binary(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        \n",
    "        test_loss, test_acc, test_recall, test_precision, test_f1 = test_step_binary(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        print(\n",
    "            f\"|-|-|-|-|-|-|-|-|-|-|-|-|-| EPOCH {epoch+1} FINISHED |-|-|-|-|-|-|-|-|-|-|-|-|-|\\n\\n\"\n",
    "            f\"train loss: {train_loss:.4f}   |   \"\n",
    "            f\"train acc: {train_acc:.4f}   |   \"\n",
    "         #   f\"train precision: {train_precision:.4f} | \"\n",
    "         #   f\"train recall: {train_recall:.4f} | \"\n",
    "            f\"train f1: {train_f1:.4f}\\n\"\n",
    "            f\"test loss: {test_loss:.4f}   |   \"\n",
    "            f\"test acc: {test_acc:.4f}   |   \"\n",
    "         #   f\"test precision: {test_precision:.4f} | \"\n",
    "          #  f\"test recall: {test_recall:.4f} | \"\n",
    "            f\"test f1: {test_f1:.4f}\\n\\n\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        results[\"train_recall\"].append(train_recall)\n",
    "        results[\"train_precision\"].append(train_precision)\n",
    "        results[\"train_f1\"].append(train_f1)\n",
    "        results[\"test_recall\"].append(test_recall)\n",
    "        results[\"test_precision\"].append(test_precision)\n",
    "        results[\"test_f1\"].append(test_f1)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_recall\":[],\n",
    "        \"train_precision\":[],\n",
    "        \"train_f1\":[],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": [],\n",
    "        \"test_recall\":[],\n",
    "        \"test_precision\":[],\n",
    "        \"test_f1\":[],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as Timer\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model_0 = CNN().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.0005)\n",
    "NUM_EPOCHS = 15\n",
    "start_time = timer()\n",
    "\n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_0_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
